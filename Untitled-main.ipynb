{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#import skimage\n",
    "\n",
    "%matplotlib notebook\n",
    "from IPython.display import display\n",
    "from scipy.misc import toimage\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter\n",
    "from typing import List,Tuple\n",
    "from time import time\n",
    "from PIL import Image,ImageOps\n",
    "from keras.models import load_model\n",
    "from io import StringIO\n",
    "from sys import argv\n",
    "infinity=-np.iinfo(np.int64).max\n",
    "glyph_names=['period', 'left_paren', 'question', 'comma', 'dash', 'colon', 'right_paren',\n",
    "       'semicolon', 'exclamation', 'left_quote', 'left_quote_1', 'right_quote', 'right_quote_1',\n",
    "       '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', \n",
    "       'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т',\n",
    "       'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', 'Ы_1', 'Ь', 'Э', 'Ю', 'Я', \n",
    "       'а_', 'б_', 'е_', 'ф_']\n",
    "glyph_symbols=['.', '(', '?', ',', '-', ':', ')', ';', '!', '«', '<', '»', '>',\n",
    "       '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', \n",
    "       'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т',\n",
    "       'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ъ', 'Ы', '|', 'Ь', 'Э', 'Ю', 'Я', \n",
    "       'а', 'б', 'е', 'ф']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'period', '.')\n",
      "(1, 'left_paren', '(')\n",
      "(2, 'question', '?')\n",
      "(3, 'comma', ',')\n",
      "(4, 'dash', '-')\n",
      "(5, 'colon', ':')\n",
      "(6, 'right_paren', ')')\n",
      "(7, 'semicolon', ';')\n",
      "(8, 'exclamation', '!')\n",
      "(9, 'left_quote', '«')\n",
      "(10, 'left_quote_1', '<')\n",
      "(11, 'right_quote', '»')\n",
      "(12, 'right_quote_1', '>')\n",
      "(13, '1', '1')\n",
      "(14, '2', '2')\n",
      "(15, '3', '3')\n",
      "(16, '4', '4')\n",
      "(17, '5', '5')\n",
      "(18, '6', '6')\n",
      "(19, '7', '7')\n",
      "(20, '8', '8')\n",
      "(21, '9', '9')\n",
      "(22, '0', '0')\n",
      "(23, 'А', 'А')\n",
      "(24, 'Б', 'Б')\n",
      "(25, 'В', 'В')\n",
      "(26, 'Г', 'Г')\n",
      "(27, 'Д', 'Д')\n",
      "(28, 'Е', 'Е')\n",
      "(29, 'Ж', 'Ж')\n",
      "(30, 'З', 'З')\n",
      "(31, 'И', 'И')\n",
      "(32, 'Й', 'Й')\n",
      "(33, 'К', 'К')\n",
      "(34, 'Л', 'Л')\n",
      "(35, 'М', 'М')\n",
      "(36, 'Н', 'Н')\n",
      "(37, 'О', 'О')\n",
      "(38, 'П', 'П')\n",
      "(39, 'Р', 'Р')\n",
      "(40, 'С', 'С')\n",
      "(41, 'Т', 'Т')\n",
      "(42, 'У', 'У')\n",
      "(43, 'Ф', 'Ф')\n",
      "(44, 'Х', 'Х')\n",
      "(45, 'Ц', 'Ц')\n",
      "(46, 'Ч', 'Ч')\n",
      "(47, 'Ш', 'Ш')\n",
      "(48, 'Щ', 'Щ')\n",
      "(49, 'Ъ', 'Ъ')\n",
      "(50, 'Ы', 'Ы')\n",
      "(51, 'Ы_1', '|')\n",
      "(52, 'Ь', 'Ь')\n",
      "(53, 'Э', 'Э')\n",
      "(54, 'Ю', 'Ю')\n",
      "(55, 'Я', 'Я')\n",
      "(56, 'а_', 'а')\n",
      "(57, 'б_', 'б')\n",
      "(58, 'е_', 'е')\n",
      "(59, 'ф_', 'ф')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(range(1000),glyph_names,glyph_symbols):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_model=load_model(r'D:\\WinPython-64bit-3.5.3.0Qt5\\model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_rows(arr:np.ndarray):\n",
    "    np.fromiter((hash(str(row)) for row in testarr),np.intp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rotate_img(img: np.ndarray,angle: float) -> np.ndarray:\n",
    "    rows,cols=img.shape[0:2]\n",
    "    r_mat=cv2.getRotationMatrix2D((rows/2,cols/2),angle,1)\n",
    "    return cv2.warpAffine(img,r_mat,(cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(img: np.ndarray) -> np.ndarray:\n",
    "    average=np.average(img)*2\n",
    "    return (img>average).astype(np.uint8)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\numpy\\core\\numeric.py:301: FutureWarning: in the future, full((3,), 1) will return an array of dtype('int32')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def convolve_1d(arr: np.ndarray,kernel=np.full((3,),1)) -> np.ndarray:\n",
    "    size=len(kernel)\n",
    "    stack=np.stack([arr[i:-(size-1-i)] for i in range(size-1)]+[arr[size-1:]])\n",
    "    pad_width=(int(np.round((size-1)/2)),int(np.floor((size-1)/2)))\n",
    "    return np.pad(np.max(stack,axis=0),pad_width,'edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\WinPython-64bit-3.5.3.0Qt5\\python-3.5.3.amd64\\lib\\site-packages\\numpy\\core\\numeric.py:301: FutureWarning: in the future, full((3,), 1) will return an array of dtype('int32')\n",
      "  format(shape, fill_value, array(fill_value).dtype), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def convolve_1d_min(arr: np.ndarray,kernel=np.full((3,),1)) -> np.ndarray:\n",
    "    size=len(kernel)\n",
    "    stack=np.stack([arr[i:-(size-1-i)] for i in range(size-1)]+[arr[size-1:]])\n",
    "    pad_width=(int(np.round((size-1)/2)),int(np.floor((size-1)/2)))\n",
    "    return np.pad(np.min(stack,axis=0),pad_width,'edge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare(filename:str) -> np.ndarray:\n",
    "    img=255-cv2.imread(filename,cv2.IMREAD_GRAYSCALE)\n",
    "    average=np.average(img)*2\n",
    "    foreground_mask=(img>average).astype(np.uint8)*255\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "    opened=cv2.morphologyEx(foreground_mask,cv2.MORPH_OPEN,kernel)\n",
    "    rect=cv2.minAreaRect(np.stack(np.nonzero(opened),axis=-1))\n",
    "    skew_angle=min(90+rect[2],abs(rect[2]))\n",
    "    angles=np.linspace(skew_angle+0.5,skew_angle-0.5,11)\n",
    "    img_list=[rotate_img(foreground_mask,-angle) for angle in angles]\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_lines(img: np.ndarray) -> List[np.ndarray]:\n",
    "    data=np.max(img,axis=-1)\n",
    "    data_c=convolve_1d_min(data)\n",
    "    nonmax=data_c<np.max(data_c)\n",
    "    return np.nonzero(np.logical_xor(nonmax[1:],nonmax[:-1]))[0].reshape(-1,2)\n",
    "    #print(percs.shape,percs_c.shape)\n",
    "    #plt.plot(percs,label='before')\n",
    "    #plt.plot(percs_c,label='after')\n",
    "    #plt.plot(np.full_like(percs,np.average(percs_c)),label='av')\n",
    "    #plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def join_lines(boundaries: List[np.ndarray]): #-> [np.ndarray]:\n",
    "    widths=np.array([line[1]-line[0] for line in boundaries])\n",
    "    threshold=np.median(widths)*0.3\n",
    "    zero_array=np.array([0,0])\n",
    "    distance_previous=[infinity]+[boundaries[i][0]-boundaries[i-1][1] for i in range(1,len(boundaries))]\n",
    "    distance_next=[boundaries[i+1][0]-boundaries[i][1] for i in range(len(boundaries)-1)]+[infinity]\n",
    "    distances=np.stack((np.array(distance_previous),np.array(distance_next)),axis=-1)\n",
    "    #print(boundaries.shape,widths.shape,distances.shape)\n",
    "    for i in range(len(boundaries)):\n",
    "        if widths[i] <= threshold:\n",
    "            if distances[i][0] < distances[i][1]:\n",
    "                boundaries[i-1][1]=boundaries[i][1]\n",
    "                boundaries[i]=zero_array\n",
    "            else:\n",
    "                boundaries[i+1][0]=boundaries[i][0]\n",
    "                boundaries[i]=zero_array\n",
    "    return boundaries[np.all(boundaries!=zero_array,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hor_boundaries(arr: np.ndarray) -> Tuple[int]:\n",
    "    nonzero_lines=np.nonzero(np.transpose(arr))[0]\n",
    "    left=np.min(nonzero_lines)\n",
    "    right=np.max(nonzero_lines)\n",
    "    return (left,right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ver_boundaries(arr: np.ndarray) -> Tuple[int]:\n",
    "    nonzero_lines=np.nonzero(arr)[0]\n",
    "    top=np.min(nonzero_lines)\n",
    "    bottom=np.max(nonzero_lines)\n",
    "    return (top,bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_letter_fragments_v(letter_arr: np.ndarray) -> np.ndarray:\n",
    "    boundaries=np.array([get_hor_boundaries(letter) for letter in letter_arr])\n",
    "    #v_boundaries=np.array([get_ver_boundaries(letter) for letter in letter_arr])\n",
    "    widths=boundaries[:,1]-boundaries[:,0]\n",
    "    #heights=v_boundaries[:,1]-v_boundaries[:,0]\n",
    "    median_width=np.median(widths)\n",
    "    #joining_threshold = np.median(widths)*0.75\n",
    "    #joining_threshold_v = np.median(heights)*0.75\n",
    "    #print(median_width,'h',joining_threshold,'v',joining_threshold_v,)\n",
    "    offset=median_width*0.25\n",
    "    offset=np.array((-offset,offset))\n",
    "    extended_boundaries=boundaries+offset\n",
    "    for i in range(1,len(boundaries)):\n",
    "        if (boundaries[i-1][0] >  extended_boundaries[i][0]) and \\\n",
    "           (boundaries[i-1][1] <  extended_boundaries[i][1]) or \\\n",
    "           (boundaries[i][0] >  extended_boundaries[i-1][0]) and \\\n",
    "           (boundaries[i][1] <  extended_boundaries[i-1][1]) or \\\n",
    "           (boundaries[i-1][1] ==  boundaries[i][0]):\n",
    "           #widths[i-1] < joining_threshold and \\\n",
    "           #widths[i] < joining_threshold and \\\n",
    "           #heights[i-1] > joining_threshold_v and \\\n",
    "           #heights[i] > joining_threshold_v or \\\n",
    "           \n",
    "            letter_arr[i]+=letter_arr[i-1]\n",
    "            letter_arr[i-1]=np.zeros_like(letter_arr[i-1])\n",
    "            #boundaries[i]=\n",
    "    return letter_arr[np.sum(letter_arr,axis=(-1,-2))>int(len(letter_arr[0])/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_statistics(letter_arr: np.ndarray) -> np.ndarray:\n",
    "    boundaries=np.array([get_hor_boundaries(letter) for letter in letter_arr])\n",
    "    v_boundaries=np.array([get_ver_boundaries(letter) for letter in letter_arr])\n",
    "    widths=boundaries[:,1]-boundaries[:,0]\n",
    "    heights=v_boundaries[:,1]-v_boundaries[:,0]\n",
    "    tops=np.transpose(v_boundaries)[0]\n",
    "    bottoms=np.transpose(v_boundaries)[1]\n",
    "    median_top=np.median(tops)\n",
    "    median_bottom=np.median(bottoms)\n",
    "    median_height=np.median(heights)\n",
    "    top_overhang=(tops-median_top)/median_height\n",
    "    bottom_overhang=(bottoms-median_bottom)/median_height\n",
    "    proportions=heights/widths\n",
    "    return np.transpose(np.stack((proportions,top_overhang,bottom_overhang,widths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_widths(letter_arr: np.ndarray) -> np.ndarray:\n",
    "    boundaries=np.array([get_hor_boundaries(letter) for letter in letter_arr])\n",
    "    return boundaries[:,1]-boundaries[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resize_letter(mask: np.ndarray) -> None:\n",
    "    boundaries=[get_ver_boundaries(mask),get_hor_boundaries(mask)]\n",
    "    boundaries[0]=(boundaries[0][0],boundaries[0][1]+1)\n",
    "    fragment=mask[slice(*boundaries[0]),slice(*boundaries[1])]\n",
    "    return (cv2.resize(fragment.astype('uint8'),(32,32),interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_letter_fragments_h(letter_arr: np.ndarray) -> np.ndarray:\n",
    "    boundaries=np.array([get_hor_boundaries(letter) for letter in letter_arr])\n",
    "    v_boundaries=np.array([get_ver_boundaries(letter) for letter in letter_arr])\n",
    "    widths=boundaries[:,1]-boundaries[:,0]\n",
    "    distances=np.pad(boundaries[1:,0]-boundaries[:-1,1],(1,1),'constant',constant_values=np.iinfo('int32').max)\n",
    "    heights=v_boundaries[:,1]-v_boundaries[:,0]\n",
    "    joining_threshold = np.median(widths)*0.65\n",
    "    joining_threshold_v = np.median(heights)*0.6\n",
    "    joining_threshold_v_m = np.median(heights)*1.1\n",
    "    to_join=[]\n",
    "    for i in range(0,len(boundaries)):\n",
    "#        if  widths[i-1] < joining_threshold and \\\n",
    "#            heights[i-1] > joining_threshold_v and \\\n",
    "        if  widths[i] < joining_threshold and \\\n",
    "            heights[i] > joining_threshold_v and \\\n",
    "            heights[i] < joining_threshold_v_m:\n",
    "            if distances[i+1]<distances[i]:\n",
    "                to_join.append(i+1)\n",
    "            else:\n",
    "                to_join.append(i)\n",
    "#    for i in range(1,len(boundaries)):\n",
    "#        if (boundaries[i-1][1] <=  boundaries[i][0]):\n",
    "#            to_join.append(i)\n",
    "    for i in range(1,len(to_join)):\n",
    "        if to_join[i]==to_join[i-1]+1:\n",
    "            to_join[i]=-1\n",
    "    to_join=[i for i in to_join if i>0]\n",
    "    if False:\n",
    "        print(to_join)\n",
    "        print(distances)\n",
    "        print(distances[1:]<distances[:-1])\n",
    "        print(np.logical_and(heights > joining_threshold_v, widths < joining_threshold))\n",
    "    for join_ind in to_join:\n",
    "        letter_arr[join_ind-1]+=letter_arr[join_ind]\n",
    "        letter_arr[join_ind]=np.zeros_like(letter_arr[join_ind-1])\n",
    "    return letter_arr[np.sum(letter_arr,axis=(-1,-2))>int(len(letter_arr[0])/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_into(letter_img: np.ndarray, count:int) -> np.ndarray:\n",
    "    boundaries=get_hor_boundaries(letter_img)\n",
    "    rgb=np.stack((letter_img,letter_img,letter_img),axis=-1).astype('uint8')\n",
    "    markers=letter_img.astype('int32')\n",
    "    for marker_value,marked_col in enumerate(np.linspace(*boundaries,count*2+1)[1::2],start=1):\n",
    "        markers[:,int(marked_col)]*=marker_value+1\n",
    "    markers-=1\n",
    "    cv2.watershed(rgb,markers)\n",
    "    return [np.where(markers==i,letter_img,np.zeros_like(letter_img)) for i in range(1,count+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_letter_blobs(letter_arr: np.ndarray) -> np.ndarray:\n",
    "    boundaries=np.array([get_hor_boundaries(letter) for letter in letter_arr])\n",
    "    v_boundaries=np.array([get_ver_boundaries(letter) for letter in letter_arr])\n",
    "    widths=boundaries[:,1]-boundaries[:,0]\n",
    "    heights=v_boundaries[:,1]-v_boundaries[:,0]\n",
    "    median_width=np.median(widths)\n",
    "    median_height=np.median(heights)\n",
    "    median_top=np.median(v_boundaries[:,0])\n",
    "    letter_arr_new=[]\n",
    "    for i in range(0,len(boundaries)):\n",
    "        if widths[i]<1.8*median_width:\n",
    "            letter_arr_new.append(letter_arr[i])\n",
    "        else:\n",
    "            try:\n",
    "                split_letter_imgs=split_into(letter_arr[i],int(np.round(widths[i]/(median_width))))\n",
    "                v_boundaries_new=np.array([get_ver_boundaries(letter) for letter in split_letter_imgs])\n",
    "                top_overhang_new=(median_top-v_boundaries_new[:,0])/median_height\n",
    "                if np.any(top_overhang_new<0.25):\n",
    "                    for img in split_letter_imgs:\n",
    "                        letter_arr_new.append(img)\n",
    "                else:\n",
    "                    letter_arr_new.append(letter_arr[i])\n",
    "            except:\n",
    "                letter_arr_new.append(letter_arr[i])\n",
    "    return np.array(letter_arr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_letters(img: np.ndarray) -> np.ndarray:\n",
    "    #filtered=np.maximum(img[:,:-1],img[:,1:])\n",
    "    #filtered=np.minimum(filtered[:,:-1],filtered[:,1:])\n",
    "    #filtered=(img>np.average(img)).astype('uint8')\n",
    "    filtered=img\n",
    "    no_markers,labeled=cv2.connectedComponents(np.transpose(filtered),connectivity=4)\n",
    "    letters=np.array([np.transpose(labeled==i) for i in range(1,no_markers)])\n",
    "    sum_threshold=int(len(letters[0])/2)\n",
    "    unmerged=letters[np.sum(letters,axis=(-1,-2))>sum_threshold]\n",
    "    return [i for i in split_letter_blobs(merge_letter_fragments_h(merge_letter_fragments_v(unmerged)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_letters_no_merge(img: np.ndarray) -> np.ndarray:\n",
    "    #filtered=np.maximum(img[:,:-1],img[:,1:])\n",
    "    #filtered=np.minimum(filtered[:,:-1],filtered[:,1:])\n",
    "    #filtered=(img>np.average(img)).astype('uint8')\n",
    "    filtered=img\n",
    "    no_markers,labeled=cv2.connectedComponents(np.transpose(filtered),connectivity=4)\n",
    "    letters=np.array([np.transpose(labeled==i) for i in range(1,no_markers)])\n",
    "    sum_threshold=int(len(letters[0])/2)\n",
    "    unmerged=letters[np.sum(letters,axis=(-1,-2))>sum_threshold]\n",
    "    return unmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_prediction(prediction,top_overhang,bottom_overhang,proportion):\n",
    "    if proportion<0.5 and -0.3>top_overhang and -0.3>bottom_overhang:\n",
    "        return '-'\n",
    "    if proportion>2.5 and 0.2>top_overhang>-0.2 and 0.2>bottom_overhang>-0.2:\n",
    "        return '|'\n",
    "    if top_overhang<-0.6:\n",
    "        if proportion<1.5:\n",
    "            return '.'\n",
    "        else:\n",
    "            return ','\n",
    "    if prediction==32:\n",
    "        if top_overhang>0.8:\n",
    "            return glyph_symbols[prediction].upper()\n",
    "        else:\n",
    "            return glyph_symbols[prediction].lower()\n",
    "    if prediction in (1,40):\n",
    "        if proportion>1.5:\n",
    "            return '('\n",
    "        else:\n",
    "            if top_overhang>0.25:\n",
    "                return 'C'\n",
    "            else:\n",
    "                return 'c'\n",
    "    if prediction in (22,37):\n",
    "        if proportion>1.25:\n",
    "            return '0'\n",
    "        else:\n",
    "            if top_overhang>0.25:\n",
    "                return 'О'\n",
    "            else:\n",
    "                return 'о'\n",
    "    if prediction in range(23,56):\n",
    "        if top_overhang>0.25:\n",
    "            return glyph_symbols[prediction].upper()\n",
    "        else:\n",
    "            return glyph_symbols[prediction].lower()\n",
    "    else:\n",
    "        return glyph_symbols[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def recognize(filename):\n",
    "    #img_list=prepare(r\"D:\\Copy\\Uni New\\GradProject\\scan3.png\")\n",
    "    #img_list=prepare(r\"D:\\Copy\\Uni New\\GradProject\\scan2.png\")\n",
    "    img_list=prepare(filename)\n",
    "    lines_list=[split_lines(img) for img in img_list]\n",
    "    lengths=[len(lines) for lines in lines_list]\n",
    "    img=img_list[np.argmax(lengths)]\n",
    "    page_split=join_lines(lines_list[np.argmax(lengths)])\n",
    "    print(len(page_split),'lines')\n",
    "    print(np.average(img))\n",
    "    line_imgs=[img[slice(*page_split[i])] for i in range(len(page_split))]\n",
    "\n",
    "    letter_masks_selected=[]\n",
    "    letter_masks_selected_unsplit=[]\n",
    "    bin_line_imgs_selected=[]\n",
    "    line_ind_=7\n",
    "    #for line_img in line_imgs[line_ind_:line_ind_+1]:\n",
    "    for line_ind in range(len(line_imgs)):\n",
    "\n",
    "        #bin_line_imgs=[(line_img>threshold) for threshold in np.arange(32,241,32)]\n",
    "        line_img=line_imgs[line_ind]\n",
    "        average_brightness=np.average(line_img)\n",
    "        bin_line_imgs=[(line_img>threshold) for threshold in \\\n",
    "                       np.arange(average_brightness/2,255,average_brightness/2).astype('int')[:12]]\n",
    "        letter_masks_list=[split_letters_no_merge(bin_line_img.astype('uint8')) for bin_line_img in bin_line_imgs]\n",
    "        widths_list=[get_widths(letter_masks) for letter_masks in letter_masks_list]\n",
    "        binc_list=[np.bincount(widths) for widths in widths_list] \n",
    "        median_width_list=[np.median(widths) for widths in widths_list] \n",
    "        width_thresholds=[(int(np.floor(median_width*0.8)),int(np.ceil(median_width*1.2))) for median_width in median_width_list]\n",
    "        sums=[np.sum(np.concatenate((binc_list[i][:width_thresholds[i][0]],\n",
    "                                     binc_list[i][width_thresholds[i][1]:]))) for i in range(len(binc_list))]\n",
    "        selected_index=np.median(np.nonzero(sums==np.min(sums))).astype('int64')\n",
    "        letter_masks_selected.append(split_letter_blobs(\n",
    "            merge_letter_fragments_h(merge_letter_fragments_v(letter_masks_list[selected_index]))))\n",
    "        bin_line_imgs_selected.append(bin_line_imgs[selected_index])\n",
    "        print('splitting line {}/{}'.format(line_ind+1,len(line_imgs)),end='\\r')\n",
    "\n",
    "    letter_masks_resized=[np.array([resize_letter(letter) for letter in line]) for line in letter_masks_selected]\n",
    "    hor_boundaries=[np.array([get_hor_boundaries(letter) for letter in line]) for line in letter_masks_selected]\n",
    "    ver_boundaries=[np.array([get_ver_boundaries(letter) for letter in line]) for line in letter_masks_selected]\n",
    "    widths=[line[:,1]-line[:,0] for line in hor_boundaries]\n",
    "    heights=[line[:,1]-line[:,0] for line in ver_boundaries]\n",
    "    proportions=[height_line/width_line for height_line,width_line in zip(heights,widths)]\n",
    "    median_heights=np.array([np.median(height_line) for height_line in heights])\n",
    "    median_widths=np.array([np.median(width_line) for width_line in widths])\n",
    "    median_tops=[np.median(line[:,0]) for line in ver_boundaries]\n",
    "    median_bottoms=[np.median(line[:,1]) for line in ver_boundaries]\n",
    "    top_overhangs=[(median_top - line[:,0])/median_height \n",
    "                   for median_top,median_height,line in zip(median_tops,median_heights,ver_boundaries) ]\n",
    "    bottom_overhangs=[(line[:,1] - median_bottom)/median_height \n",
    "                   for median_bottom,median_height,line in zip(median_bottoms,median_heights,ver_boundaries) ]\n",
    "    distances=[line[1:,0]-line[:-1,1] for line in hor_boundaries]\n",
    "    dist_binc=np.bincount(np.abs(np.concatenate(distances))).astype('float')\n",
    "    dist_binc+=1\n",
    "    space_threshold=np.argmax(dist_binc[:-1]/dist_binc[1:])\n",
    "    space_after=[np.pad(line>(space_threshold),(0,1),'constant') for line,median_width in zip(distances,median_widths)]\n",
    "    predictions=[np.argmax(nn_model.predict((line_imgs).reshape(-1,32,32,1)),axis=-1) for line_imgs in letter_masks_resized]\n",
    "\n",
    "    output_io=StringIO()\n",
    "    for predictions_line,space_after_line,top_overhang_line,bottom_overhang_line,proportion_line \\\n",
    "    in zip(predictions,space_after,top_overhangs,bottom_overhangs,proportions):\n",
    "        for prediction,space_after_letter,top_overhang,bottom_overhang,proportion \\\n",
    "        in zip(predictions_line,space_after_line,top_overhang_line,bottom_overhang_line,proportion_line):\n",
    "            output_io.write(correct_prediction(prediction,top_overhang,bottom_overhang,proportion))\n",
    "            output_io.write(' ') if space_after_letter else None\n",
    "        output_io.write('\\n')\n",
    "    return output_io.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'Пять членов РеФорм-клуба иереглянулиcь, По вcc-1')\n",
      "(1, 'вероятноcти, cердца их за6илиcь быcтрее, ибо даже для')\n",
      "(2, 'хороших игроков cтавка была веcьма крупной! Но они')\n",
      "(3, 'не хотели выказывать cвоего волнения и по предложе-')\n",
      "(4, 'нию Cэмюэля Фаллентина уcелиcь за карточный cтол.')\n",
      "(5, '-- Я не отдал бы cвоей доли пари даже в том cлу-')\n",
      "(6, 'чае, еcли 6ы за четыре тыcячи фунтов мне пред.3ожили')\n",
      "(7, 'три тыcячи девятьcот де8яноcто девятьг заметил, cа-')\n",
      "(8, 'дяcь, Эндрю Cтюарт')\n",
      "(9, 'Cтрелка чаcов показывала воcемь чаcов cорок две')\n",
      "(10, 'минуты. Игроки взяли карты, но каждое мгновение их')\n",
      "(11, 'взгляд уcтремлялcя на чаcы. Моэкно cмело утверждать,')\n",
      "(12, 'что, как ни велика 6ыла их уведенноcть в выигрыше,')\n",
      "(13, 'никогда минуты не тянулиcь для них так долго!..')\n",
      "(14, '-- Воccмь чаcов cорок три минуты,-- cказал Томаc')\n",
      "(15, 'Флэнаган, cнимая колоду, предложенную ему Готье')\n",
      "(16, 'Ральфом.')\n",
      "(17, 'Наcтупило минутное молчание В обширном cалоне')\n",
      "(18, 'C4дло тихо, но c улицы доноcилcя гул толпы. из которо-')\n",
      "(19, 'го иногда выделялиcь резкие выкрики. Маятник cтен-')\n",
      "(20, 'ных чаcов отбивал cекунды c математичеcкой точноcтью.')\n",
      "(21, 'Каждыа игрок мог cоcчитать его удары, отчетливо раз-')\n",
      "(22, 'давав|ииеcя в ушах.')\n",
      "(23, '-- Воcемь чаcов cорок четыре минуты! -- cказал')\n",
      "(24, 'Джон Cэлливан голоcом, в котором cлышалоcь недоль-')\n",
      "(25, 'ное волнение.')\n",
      "(26, 'Еще одна минута -- и пари будет выиграно. Эндрю')\n",
      "(27, 'Cтюарт и его партнеры больше не играли. Они броcилх')\n",
      "(28, 'карты на cтол. Они cчитали cекунды.')\n",
      "(29, 'На cороковой cекунде -- ничего, На пятидеcятой --')\n",
      "(30, 'вcе еюде ничего!')\n",
      "(31, 'На пятьдеcят пятой cекунде c улицы донеccя шум,')\n",
      "(32, 'походивший на раcкаты грома, поcлышалиcь аплодиc-')\n",
      "(33, 'менты, «рики «ура» и даже проклятия,-- вcе это cлилоcь')\n",
      "(34, 'д общий неcмолкаемый гул.')\n",
      "(35, 'Игроки поднялиcь cо cвоих меcт.')\n",
      "(36, 'На пятъдеcят cедьмой cекунде ддерь cалона отдорн-')\n",
      "(37, 'лаcь, и маятник чаcов не уcпел еиде качнутьcя в хиеcти-')\n",
      "(38, 'деcятый раз, как на пороге показалcя Филеаc Фогг в')\n",
      "(39, 'cопровождении обеэумевшей толпы, которая наcильно')\n",
      "(40, 'норвалаcь за ним н клу6.')\n",
      "(41, '-- Вот и я, гоcпода,-- произнеc он cпдкойным')\n",
      "(42, 'голоcом.')\n",
      "(43, ', 206 -')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\WinPython-64bit-3.5.3.0Qt5\\\\python-3.5.3.amd64\\\\lib\\\\site-packages\\\\ipykernel\\\\__main__.py', '-f', 'D:\\\\WinPython-64bit-3.5.3.0Qt5\\\\settings\\\\runtime\\\\kernel-58a51773-b7af-43f7-8c9c-8f63ff6c2ce7.json']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d558eee079c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrecognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-5c2c39c1c225>\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[1;31m#img_list=prepare(r\"D:\\Copy\\Uni New\\GradProject\\scan3.png\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[1;31m#img_list=prepare(r\"D:\\Copy\\Uni New\\GradProject\\scan2.png\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlines_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-94736f40c1de>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mforeground_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPH_RECT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print(argv)\n",
    "    for filename in argv:\n",
    "        recognize(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
